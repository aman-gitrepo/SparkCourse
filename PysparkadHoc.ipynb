{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b684b64-0e62-4a38-a05b-1d3ef50e9e0c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField , StructType , StringType, IntegerType\n",
    "from pyspark.sql.functions import col , rand , when\n",
    "from pyspark.sql import SparkSession , Row , SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c7d4795-52c2-40bc-9e4e-5cf07ccda6e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+----------------+\n",
      "| Id|Name|Age|Area of Interest|\n",
      "+---+----+---+----------------+\n",
      "|  1|jack| 22|    Data Science|\n",
      "|  2| Leo| 21|  Data Analytics|\n",
      "|  3|Luke| 24|   Microservices|\n",
      "|  4|Mark| 21|  Data Analytics|\n",
      "+---+----+---+----------------+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|              Age|\n",
      "+-------+-----------------+\n",
      "|  count|                4|\n",
      "|   mean|             22.0|\n",
      "| stddev|1.414213562373095|\n",
      "|    min|               21|\n",
      "|    max|               24|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-------+-----+\n",
      "|summary|  Age|\n",
      "+-------+-----+\n",
      "|  count|    4|\n",
      "|   mean| 22.0|\n",
      "| stddev|1.414|\n",
      "|    min|   21|\n",
      "|    max|   24|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark  = SparkSession.builder.master('local[*]').appName('test').config().getorCreate()\n",
    "people = Row(\"Id\" ,\"Name\", \"Age\", \"Area of Interest\")\n",
    "p1 = people(\"1\" ,\"jack\", 22, \"Data Science\")\n",
    "p2 = people(\"2\" ,\"Leo\" ,21 ,\"Data Analytics\")\n",
    "p3 = people(\"3\" ,\"Luke\", 24, \"Microservices\")\n",
    "p4 = people(\"4\" ,\"Mark\" ,21 ,\"Data Analytics\")\n",
    "data = [p1,p2,p3,p4]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "df.show()\n",
    "\n",
    "ageDescribe = df.describe('Age')\n",
    "ageDescribe.show()\n",
    "\n",
    "ageDescribe = ageDescribe.withColumn('Age',col('Age').cast(StringType()))\n",
    "ageDescribe = ageDescribe.withColumn('Age',when(ageDescribe['summary'] == 'stddev',1.414).otherwise(ageDescribe['Age']))\n",
    "ageDescribe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e8a1813-7ba1-45c6-99fb-abdd8dfb536e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+\n",
      "| id|              rand1|              rand2|\n",
      "+---+-------------------+-------------------+\n",
      "|  0|0.03422639313807285| 0.9388044512577215|\n",
      "|  1| 0.3654625958161396| 0.3943255396952755|\n",
      "|  2| 0.4175019040792016|0.23260361399084917|\n",
      "|  3|0.16452185994603707|0.02339183228862929|\n",
      "|  4|0.18141810315190554| 0.8894415403143504|\n",
      "|  5| 0.9697474945375325| 0.5956629641640896|\n",
      "|  6|0.34084319330900115| 0.2762195585886885|\n",
      "|  7| 0.4725977369833597| 0.8378244793454831|\n",
      "|  8| 0.5996723933366402| 0.6340859398860077|\n",
      "|  9| 0.6396141227834357|0.49326717925251506|\n",
      "+---+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df = SQLContext(sc).range(0,10).withColumn('rand1',rand(seed = 10)).withColumn('rand2',rand(seed = 22))\n",
    "df = SparkSession.builder.getOrCreate().range(0,10).withColumn('rand1',rand(seed = 10)).withColumn('rand2',rand(seed = 22))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9f43190-8d5e-4b6c-aac5-ae178fdae5e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|stats|              Values|\n",
      "+-----+--------------------+\n",
      "|  cov|-0.00253982823215...|\n",
      "| corr|-0.03065022425988...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cov =  df.cov('rand1','rand2')\n",
    "df_corr =  df.corr('rand1','rand2')\n",
    "\n",
    "dataType = [(\"cov\",df_cov),(\"corr\",df_corr)]\n",
    "schemaType = StructType([StructField('stats',StringType(),True),StructField('Values',StringType(),True)])\n",
    "df_ = spark.createDataFrame(data = dataType , schema = schemaType )\n",
    "df_.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40dac57-f900-4222-8ce0-af054d747e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
